
---

# ✅ **CLOSED-LOOP AUTOMATION — STAGE-BY-STAGE CHECKLIST**

### *With Prometheus, Kafka, Automation Engine (StackStorm/Rundeck), Nornir/Ansible, Grafana, and full remediation flow.*

---

# **0. PREPARATION & INFRASTRUCTURE (Before Running Closed Loop)**

### **0.1 Tooling Dependencies**

* [ ] Prometheus installed for metrics collection
* [ ] Kafka cluster running (3-node minimum recommended)
* [ ] Kafka topics:

  * `telemetry.raw` (raw device telemetry)
  * `telemetry.parsed`
  * `events.interface-errors`
  * `automation.remediation-requests`
  * `automation.remediation-results`
* [ ] Kafka Schema Registry configured (if using Avro/JSON schema)
* [ ] Loki or Elasticsearch/Logstash for logs
* [ ] StackStorm / Rundeck automation engine installed
* [ ] Ansible / Nornir / pyATS runners validated
* [ ] Secrets stored in Vault / Jenkins credentials
* [ ] Grafana dashboards configured for:

  * telemetry
  * alerts
  * automation actions
  * resolution statistics

---

# **1. TELEMETRY COLLECTION STAGE (Continuous)**

### **1.1 Device Telemetry Agents**

* [ ] Install gNMI collectors, SNMP pollers, or streaming telemetry agents
* [ ] Configure push or pull model (device → collector → Kafka/Prometheus)
* [ ] Export metrics:

  * interface input errors
  * CRC errors
  * discards / drops
  * speed/duplex
  * link-flap counters
* [ ] Ensure telemetry timestamp & device tags present

### **1.2 Push Telemetry Into Kafka**

* [ ] Collector publishes raw telemetry to `telemetry.raw`
* [ ] Log agents push syslogs to Loki/ELK (optional: also Kafka stream)

### **1.3 Prometheus Scraping**

* [ ] Prometheus scrapes exporter or adapter that reads from Kafka OR direct device exporter
* [ ] Ensure key metrics are in Prometheus:

  * `interface_errors`
  * `crc_errors`
  * `rx_drops`
  * `link_flap_events`

---

# **2. STREAM PROCESSING & ANOMALY DETECTION (Kafka Stage)**

### **2.1 Kafka Stream Processing**

Using Kafka Streams / Flink / Spark Streaming:

* [ ] Subscribe to `telemetry.raw`
* [ ] Parse, normalize and write structured telemetry → `telemetry.parsed`
* [ ] Apply anomaly detection rules:

  * sudden spike in interface errors
  * CRC exceeding threshold
  * error_rate > historical baseline
  * correlated flapping
* [ ] If anomaly detected → publish event to:

  * `events.interface-errors`

### **2.2 Optional ML/Anomaly Detection**

* [ ] Use ML model to detect unusual patterns
* [ ] Feed ML model with historical telemetry stored in Kafka / object-store
* [ ] Auto-classify event type:

  * physical layer
  * speed/duplex mismatch
  * routing adjacency issue
  * QoS buffer oversubscription

---

# **3. ALERT GENERATION & ROUTING**

### **3.1 Prometheus Alert Rules**

* [ ] Define alert thresholds:

  * `interface_errors > X`
  * `crc_errors increasing`
  * `drops > baseline`
* [ ] Alerts forwarded to Alertmanager

### **3.2 Alert Routing**

* [ ] Alertmanager groups alerts per device and interface
* [ ] Webhook sent to StackStorm/Rundeck with:

  * device
  * interface
  * error type
  * timestamp
  * Prometheus snapshot

---

# **4. AUTOMATION ENGINE (StackStorm / Rundeck) — DECISION GATE**

### **4.1 Receive Alert**

* [ ] Automation engine receives webhook
* [ ] Validate alert payload (device, interface, metrics)
* [ ] Check if device is allowed for auto-remediation
* [ ] Check maintenance window / policy
* [ ] Determine severity

### **4.2 Decision Point**

* [ ] If severity low → auto-remediate
* [ ] If severity medium/high → request approval
* [ ] If no response in X minutes → fallback action defined

---

# **5. DATA COLLECTION (Troubleshooting Inputs)**

### **5.1 Automated Troubleshooting Commands**

* [ ] Fetch:

  * `show interface <X>`
  * `show controllers <X>`
  * `show log last 200`
  * `show ip route` or protocol-specific (OSPF/BGP)
* [ ] If needed:

  * run selective packet capture
  * gather interface history
  * check error counters over last N intervals

### **5.2 Store Troubleshooting Artifacts**

* [ ] Send logs to:

  * S3/MinIO
  * Elasticsearch/Loki
  * Kafka topic (`automation.tshoot-logs`)

---

# **6. ANALYSIS LAYER**

### **6.1 Rule-Based Analysis**

* [ ] If CRC errors ⇒ Likely physical
* [ ] If input errors + no CRC ⇒ queue drops or QoS
* [ ] If flaps ⇒ speed/duplex mismatch or cable

### **6.2 Cross-Correlation**

* [ ] Search logs for:

  * link down
  * negotiation failures
  * duplex mismatch
* [ ] Evaluate increment pattern:

  * last 5 min vs last 1 hour

### **6.3 Identify Possible Remediation Actions**

* [ ] Clear counters (safe)
* [ ] Shut/no-shut interface
* [ ] Force speed/duplex
* [ ] Reseat optics (if hardware)
* [ ] Adjust QoS

---

# **7. REMEDIATION EXECUTION (Ansible / Nornir / pyATS)**

### **7.1 Pre-Check**

* [ ] Ensure device reachable
* [ ] Ensure automation login works
* [ ] Save device config (backup)

### **7.2 Primary Safe Actions**

* [ ] Clear counters
* [ ] Re-check if fast recovery happens

### **7.3 Secondary Actions (Higher Impact)**

* [ ] Shut/no-shut interface
* [ ] Adjust speed/duplex
* [ ] Apply QoS tuning
* [ ] Reset transceiver (if platform supports)
* [ ] Re-enable port-channel member

### **7.4 Post-Action Collection**

* [ ] Re-run `show interface`
* [ ] Compare counters (should reset or stabilize)
* [ ] Write logs to Kafka: `automation.remediation-results`

---

# **8. VERIFICATION LOOP**

### **8.1 Automated Validation**

* [ ] Check whether interface errors have:

  * stopped increasing
  * returned to normal baseline
  * interface remains UP
* [ ] Prometheus executes follow-up rule:

  * Compare post-remediation metrics within 1–3 minutes
* [ ] If error continues → escalate to human
* [ ] If resolved → automatically close alert

### **8.2 Close Alert**

* [ ] Auto-send closure to Alertmanager
* [ ] Update ticket / incident (ServiceNow / Jira) via API
* [ ] Publish success event to Kafka

---

# **9. LOGGING, AUDIT & DB UPDATES**

### **9.1 Log All Details**

* [ ] Raw telemetry
* [ ] Analysis summary
* [ ] Remediation steps
* [ ] Post-check results

### **9.2 Store in DB/Kafka**

* [ ] MySQL/Elastic/Kafka used as persistent store
* [ ] Write:

  * `automation.remediation-requests`
  * `automation.remediation-results`

---

# **10. FEEDBACK LOOP & SELF-IMPROVEMENT**

### **10.1 Update Policies**

* [ ] Update thresholds based on frequency
* [ ] Add new rules when recurring issues detected
* [ ] Improve remediation logic based on results

### **10.2 ML Model Enhancement**

* [ ] Train model on:

  * device type
  * port type
  * vendor OS
  * historical behavior

---

# **11. DASHBOARDS & VISIBILITY**

### **11.1 Grafana Views**

* [ ] Live interface error trends
* [ ] Auto-remediation frequency
* [ ] Success/failure rates
* [ ] Worst devices (Top N)
* [ ] Kafka consumer lag (health of telemetry pipeline)
* [ ] SLA compliance indicators

### **11.2 Operator Summary Panels**

* [ ] Last 24 hours anomaly count
* [ ] Tickets automatically resolved
* [ ] Human escalations
* [ ] MTTR reduction metrics

---

# **12. SAFETY MECHANISMS**

### **12.1 Guardrails**

* [ ] Do NOT auto-remediate on:

  * Core uplinks
  * Firewall interfaces
  * Routing adjacencies
* [ ] Mandatory human approval for multi-device actions
* [ ] Maximum 1 remediation per device in 10 min
* [ ] Circuit breaker:

  * If more than X devices show same pattern → stop automation

---

# **13. OPTIONAL ADVANCED FEATURES**

### **Kafka Enhancements**

* [ ] Use Kafka Connect to sink telemetry into:

  * S3
  * Elasticsearch
  * Snowflake
* [ ] Use Kafka Streams for:

  * multi-device correlation
  * cross-site anomaly detection
* [ ] Use KSQL for live queries:

  * “SELECT * FROM parsed_telemetry WHERE crc_errors > 1000 EMIT CHANGES;”

### **AIOps / ML**

* [ ] Root cause classification model
* [ ] Predictive interface failure (degradation signals)

---

# ✔ You now have a complete, enterprise-grade closed-loop automation checklist

Perfect for:

* NOC teams
* NetDevOps automation team
* SRE-style network reliability engineering
* Documentation, audits, runbooks, or onboarding

---

```
                             CLOSED-LOOP AUTOMATION
                (Interface Error Detection → Auto-Troubleshoot → Repair)
   ┌────────────────────────────────────────────────────────────────────────────┐
   │                                NETWORK                                   │
   │    ┌──────────┐    ┌──────────┐    ┌──────────┐    ┌──────────┐            │
   │    │ Router A │    │ Router B │    │ Switch C │    │ Router D │ ... (N)   │
   │    └──────────┘    └──────────┘    └──────────┘    └──────────┘            │
   │       │               │               │               │                   │
   │  Telemetry (gNMI/NETCONF/SSH/SNMP/Flow) / Syslog / Streaming Telemetry    │
   └────────┬──────────────┬──────────────┬──────────────┬────────────────────┘
            │              │              │              │
            ▼              ▼              ▼              ▼
   ┌─────────────────────────────────────────────────────────────────────────┐
   │            TELEMETRY & LOG COLLECTION LAYER (Agents / Collectors)      │
   │  - Telegraf / collectd / fluentd / Vector / Prometheus exporters        │
   │  - Telemetry agents (gNMI collectors, streaming)                        │
   │  - Syslog agents -> Log pipeline (Loki or ELK: Logstash/Fluentd -> ES)  │
   └────────────┬───────────────────────────────────────────────┬────────────┘
                │                                               │
                ▼                                               ▼
   ┌──────────────────────────┐                      ┌───────────────────────────┐
   │   METRICS TIME SERIES    │                      │      LOG STORAGE &        │
   │      (Prometheus)        │                      │     ANALYTICS (Loki / ES) │
   └─────────┬────────────────┘                      └─────────┬─────────────────┘
             │                                              │
             │  PromQL Alerts                                 │
             │  (interface_errors > 0, or error_rate rising)  │
             ▼                                              ▼
   ┌─────────────────────────────────────────────────────────────────────────┐
   │                         ALERTMANAGER / RULES                            │
   │  - Aggregate alert -> group by device/interface                          │
   │  - Silence / dedupe / routing rules                                      │
   │  - Configure webhook -> POST to Automation Engine                        │
   └────────────┬────────────────────────────────────────────────────────────┘
                │
                ▼
   ┌─────────────────────────────────────────────────────────────────────────┐
   │                    AUTOMATION ORCHESTRATOR                              │
   │   (StackStorm / Rundeck / n8n / Apache Airflow / custom webhook svc)    │
   │  - Receives alert webhook (device, interface, metric snapshot, time)     │
   │  - Lookup runbook (per-device / per-interface type)                      │
   │  - Decide: Auto-remediate? (policy) or escalate to human                 │
   └────────────┬────────────────────────────────────────────────────────────┘
                │
   ┌────────────┼───────────────────────────────────────────────────────────┐
   │            │                                                           │
   │ (A) Auto   │ (B) Escalate to Human (if risky / threshold)                │
   │ remediate  │ - Send Slack/Email w/ suggested runbook                     │
   │ workflow   │ - Wait for approval (timeout fallback may allow auto)       │
   │            │                                                           │
   └─────┬──────┴───────────────────────────────────────────────────────────┘
         │
         ▼
   ┌─────────────────────────────────────────────────────────────────────────┐
   │                     DATA COLLECTION (for troubleshooting)               │
   │  - Run telemetry collectors (gNMI/NETCONF/SSH) to fetch:                │
   │      * show interfaces <ifname> counters (input errors, CRC, drops)     │
   │      * show log last 1000 lines                                        │
   │      * show ip route / bgp summary / arp table                         │
   │      * tcpdump or pcap on interface (selective capture)                │
   │  - Store raw outputs as artifacts (S3 or DB) & index logs               │
   └────────────┬────────────────────────────────────────────────────────────┘
                │
                ▼
   ┌─────────────────────────────────────────────────────────────────────────┐
   │                         ANALYSIS / Triage LAYER                         │
   │  - Rule-based analysis (Elastic Watcher / ElastAlert / custom rules)    │
   │     * e.g., if CRC errors > X => likely physical layer (cabling/duplex) │
   │     * if errors correlated with speed/duplex flaps => suspect mismatch  │
   │  - ML anomaly detection (optional) on time-series                       │
   │  - Correlate logs + metrics + config changes                             │
   │  - Determine candidate remediation actions (bounce, clear counters,     │
   │    change speed/duplex, increase buffers, change QoS, reprogram ACL)    │
   └────────────┬────────────────────────────────────────────────────────────┘
                │
                ▼
   ┌─────────────────────────────────────────────────────────────────────────┐
   │                         REMEDIATION ENGINE                              │
   │  (Ansible / Nornir / pyATS / Salt)                                      │
   │  - Fetch device creds from Vault (HashiCorp Vault / Creds store)        │
   │  - Execute safe runbook steps with checks:                              │
   │      1) Non-disruptive: clear counters (clear counters)                 │
   │      2) Reconfigure (change interface speed/duplex) with dry-run first  │
   │      3) Bounce interface (shutdown/no shutdown) on single device        │
   │      4) Apply ACL or QoS tweak (if related)                            │
   │      5) Capture post-action outputs                                     │
   │  - Use transaction/backup: save config before change, allow rollback     │
   │  - Record action status & logs to artifacts / DB                        │
   └────────────┬────────────────────────────────────────────────────────────┘
                │
                ▼
   ┌─────────────────────────────────────────────────────────────────────────┐
   │                       VERIFICATION & MONITORING                         │
   │  - Run post-checks:                                                     │
   │      * re-read interface counters (should drop to baseline)             │
   │      * check interface operational state                                │
   │      * run connectivity tests (ping next-hop, traffic test)            │
   │  - If OK:                                                                │
   │      * Close alert in Alertmanager                                      │
   │      * Update Incident/Ticket (Jira/ServiceNow)                         │
   │      * Log resolution to DB / artifact storage                           │
   │  - If NOT OK:                                                           │
   │      * escalate to human operator                                        │
   │      * optionally run higher-impact remediation (with human approval)    │
   └────────────┬────────────────────────────────────────────────────────────┘
                │
                ▼
   ┌─────────────────────────────────────────────────────────────────────────┐
   │                       FEEDBACK & LEARNING LAYER                         │
   │  - Feed the analysis/remediation outcome back to:                        │
   │      * Monitoring rules (adjust thresholds, create new alerts)          │
   │      * Runbooks (improve automated actions or add human checks)         │
   │      * ML models (train on labeled incidents)                           │
   │  - Metrics & Dashboards: Grafana (Prometheus + Loki)                    │
   │      * show incidents over time, auto-remediations succeeded/failed     │
   │  - Audit trail & compliance storage (DB or SIEM)                        │
   └─────────────────────────────────────────────────────────────────────────┘
```

---

## Quick mapping: components → recommended open-source tools

* Metrics collection: **Prometheus** (node/exporters or device exporters, Telegraf with Prometheus output)
* Logs & packet captures: **Loki** (lightweight) or **Elasticsearch + Logstash**
* Alerting & routing: **Alertmanager** (Prometheus)
* Automation orchestrator (webhook receiver + workflows): **StackStorm**, **Rundeck**, or **n8n**
* Remediation executor: **Ansible** / **Nornir** / **pyATS** (for device-safe network changes)
* Secrets: **HashiCorp Vault** or Jenkins credentials store
* Artifact storage: S3 / MinIO / Jenkins artifact store
* Analysis rules: **ElastAlert**, **Kapacitor**, simple Python rule engine, or ML library (scikit-learn)
* Visualization & dashboards: **Grafana** (Prometheus + Loki datasources)
* Ticketing integration: **Jira** / **ServiceNow** (via API)

---

## Minimal safe runbook example (abstract)

1. Alertmanager fires for `interface_input_errors > 100` on Router A Gi0/1.
2. Automation engine receives webhook -> runbook "net-if-error".
3. Collect: `show interface Gi0/1`, `show logging last 500`, `show controllers Gi0/1`. Save artifacts.
4. Analyze: CRC errors present + link flaps -> probable physical issue. Suggested action: check duplex/speed and re-negotiate, or bounce port.
5. If policy = auto-remediate: run Ansible task to `shutdown` → wait → `no shutdown` on Gi0/1 (with pre-backup and retries). If risky device: escalate to human.
6. Post-check: `show interface Gi0/1` errors falling to 0 → close alert → update ticket. If not fixed -> escalate.

---

## Safety & best-practices (must-haves)

* Always take config backup before any change.
* Prefer non-disruptive actions first (clear counters, admin reset on 1 device) before broad disruptive actions.
* Canary remediation on single device (or small set) before sweeping fix.
* Enforce role-based approval for high-impact actions.
* Add throttling and circuit-breaker to avoid cascading changes.
* Maintain audit trail for every automated action and store outputs.
* Use idempotent playbooks and validate device capability before action.

---

